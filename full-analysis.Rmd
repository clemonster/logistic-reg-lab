---
title: "Logistic Regression"
author: "MAP541"
date: "Winter 2017/2018"
output:
   html_document:
    css: hideOutput.css
    includes:
      in_header: hideOutput.script
---


```{r Knitr_Global_Options, include=FALSE}
library(knitr)
opts_chunk$set(warning = FALSE, message = FALSE, cache = TRUE, autodep = TRUE, tidy = FALSE)
```

In this lab, we will rely on the following packages

```{r}
library(tidyverse)
library(questionr)
library(plotluck)
```


# Age dependency of the Coronary Heart Disease

The age and the presence or the absence of the CHD have been measured for 100 patients. The dataset is store in a tabulated file __CHD.txt__: on each line, we have a variable `AGE` giving the age in yeat, a variable `CHD` having value 1 if the disease is present and otherwise, as well a an `ID` and a age group number `AGRP`.

1. Read the data set with `read_table` and look at it.

```{r}
CHD <- read.table("data/CHD.txt", header = TRUE)
```


2. Transform the variable that are factors into __R__ factors. 

```{r}
CHD <- CHD %>% mutate(
  AGRP = as.factor(AGRP),
  CHD = as.factor(CHD)
)
```


3. Now, look at the `summary` of the dataset to spot (and correct) possible remaining issues.

```{r}
summary(CHD)
```
There doesn't seem to be any issues or strange values in the data.


4. Visualize the repartition of the patient medical state globally, by age or by age group.

Globally
```{r}
ggplot(data = CHD, mapping = aes(CHD)) +
  geom_bar()
```

By age group
```{r}
ggplot(data = CHD, mapping = aes(x = AGRP, fill = CHD)) +
  geom_bar(position = "fill")
```

By age
```{r}
ggplot(data = CHD, mapping = aes(AGE, CHD))+
  geom_point()
```
To see a bit better, we can use the `geom_jitter` option. This randomly "shakes" our data for visualization purposes.

```{r}
ggplot(data = CHD, aes(x = AGE, y = CHD))+ 
  geom_jitter(height = .1, width = 0)
```


<!-- linear_model = lm(as.numeric(CHD) ~ AGE, data=CHD) -->
<!-- ggplot(data = CHD, aes(x = AGE, y = CHD, ymin=-1, ymax=2) ) + geom_point(alpha = .5) + geom_abline(intercept = linear_model$coefficients[1], slope = linear_model$coefficients[2]) -->


5. Compute the proportion of disease among each age group as well as the mean age.

```{r}
agrp_summary <- CHD %>% 
  group_by(AGRP) %>% 
  summarise(mean_age = mean(AGE), proportion_dead = sum(CHD == 1)/n())

agrp_summary
```


5. Compute the coefficients of the logistic regression of  `CHD` with respect to `AGE`. How to interpret them?

```{r}
log.fit.age <- glm(CHD ~ AGE, family =  binomial, data = CHD)
summary(log.fit.age)
```
So we see there is a very significant effect of Age on the probability of having coronary heart disease. 
The effect is positive (meaning that older patients have a higher probability of having CHD)

Same question with AGRP instead of AGE.

```{r}
log.fit.agrp <- glm(CHD ~ AGRP, family =  binomial, data = CHD)
summary(log.fit.agrp)
```

Here again, there is a strong association of age group with CHD (note that since the coefficients for some of the age groups are highly significant, we say age group has an effect, even if for some other age groups the coefficients are not statistically significant).
We see again that the older the age, the higher the probability of having CHD.
Since the AIC of the first model was lower, we would prefer the first model. This is not surprising as the first model captures the effect of age by using only one parameter, while AGRP uses 7 parameters.

6. The function `odds.ratio` from the __questionr__ package allow to compute the odds ratio, as well as a confidence interval and p-values. How to interpret those results?

```{r}
odds.ratio(log.fit.age)
```

Let's check these confidence intervals manually. We should have with probability .95:
$$\beta_1 \in [\hat\beta_1 - z_{1-\alpha/2} * \hat\sigma ; \hat\beta_1 + z_{1-\alpha/2} * \hat\sigma ]$$
$$\beta_1 \in [.11 - 1.96 * 0.02409; .11 + 1.96 * 0.02409 ]$$
And so because $\exp(x)$ is bijective, we have with prob .95:
$$exp(\beta_1) \in [exp(.11 - 1.96 * 0.02409) ; exp(.11 + 1.96 * 0.02409) ]$$
Let's compute this interval
```{r}
c(exp(.11 - 1.96 * 0.02409) , exp(.11 + 1.96 * 0.02409))
```
This is indeed what we had for the confidence interval with the `odds.ratio` function.
```{r}
log.fit.age$coefficients
```


So when AGE increases by 1 year, the odds of having CHD are multiplied by $e^{0.111} = 1.117$. The association is very significant. This confirms what we said before: age is strongly positively associated with the probability of having CHD.

7. Visualize the per group proportion and the logistic regression prediction.

```{r}
CHD_grid <- data.frame(AGE = seq(20,70,length=100))
CHD_grid <- CHD_grid %>% mutate(pred =  predict(log.fit.age, CHD_grid, type = "response"))
```


```{r}
ggplot(agrp_summary, aes(x = mean_age, y = proportion_dead)) + geom_point(aes(col="prop")) +
  geom_point(data = CHD, aes(x = AGE,y = as.numeric(CHD==1), col="CHD")) + 
  scale_color_discrete(name = "Legend") +
  geom_segment(data = data.frame(x = c(19,29,34,39,44,49,54,59,69), y = rep(0,9)), 
                aes(x = x, y = y, xend = x, yend = y+1), linetype = 2, color = "black") +
  geom_line(data = CHD_grid, aes(x = AGE, y = pred, col = "pred"))
```


8. How to interpret the result of __summary__?

```{r}
summary(log.fit.age)
```


9. The confusion matrix, the cross table of the prediction vs the truth, is a good way to check the quality of a model. How to compute it?

```{r}
confusion <- table(list(predicted = as.numeric(predict(log.fit.age, type = "response") > .5), observed = CHD$CHD))
confusion
```
Let's compute the prediction error
```{r}
(confusion[1,2] + confusion[2,1]) / length(CHD$CHD)
```


10. How to test a model with a polynomial dependecy?

```{r}
log.fit.poly <- glm(CHD ~ AGE + I(AGE^2), family = binomial, data = CHD)
summary(log.fit.poly)
```
What we see is that now none of our predictors are significant. The AIC increased by two compared to the linear dependency model. This is not a good model.

11. Verify with a cross validation scheme that those numbers are not too optimistic.

```{r}
V <- 5
Vf <- sample(nrow(CHD)) %% V + 1

table_list <- vector("list", V) 
for (v in 1:V) {
  CHD_train <- CHD[Vf != v,]
  CHD_test <- CHD[Vf == v,]
  CHD_logit_train <- glm(CHD~AGE, family=binomial(link="logit"), data=CHD_train)### ATTENTION !!!! sur le train
  
  CHD_pred <- predict(CHD_logit_train, newdata = CHD_test, type = "response")
  CHD_pred <- mutate(CHD_test, pred_prop = CHD_pred,
                   pred = factor(pred_prop >= .5, levels = c(F,T), labels = c("No","Yes")))

  table_list[[v]] <- table(CHD_pred %>% select(CHD, pred))/nrow(CHD_test)
}
mean_table <- Reduce("+", table_list)/V
mean_table
```


12. Compute the True Positive proportion, the True Negative proportion as well as the False Positive and False Negative ones. Compare with the Precision, the Recall and the Accuracy.




<!-- mydata = CHD -->
<!-- mylogit <- glm(CHD ~ ., data = CHD, family = "binomial") -->
<!-- summary(mylogit) -->
<!-- prob=predict(mylogit,type=c("response")) -->
<!-- mydata$prob=prob -->
<!-- library(pROC) -->
<!-- g <- roc(CHD ~ prob, data = mydata) -->
<!-- plot(g) -->
<!-- auc(g) -->





# Credit default

The aim is to predict whether a client will have a credit card default from a few simple covariates. In the __ISLR__ package, there is a dataset `Default` which measures
for 10000 clients 4 variables:
- `default`: a factor variable corresponding to the presence and the absence of default
- `student`: a factor variable having value Yes for a student and No otherwise
- `balance`: the average credit card balance at the end of the month
- `income` : the customer income


1. Read the data and obtain their summary.

<div class="hiddensolution">
```{r}
library(ISLR)
data(Default)
glimpse(Default)
summary(Default)
```
</div>

2. Visualize each variable with the `plotluck` function from the __plotluck__ package.

<div class="hiddensolution">
```{r}
plotluck(Default, default ~ 1)
plotluck(Default, balance ~ 1)
plotluck(Default, income ~ 1)
plotluck(Default, student ~ 1)
plotluck(Default, default ~ balance)
plotluck(Default, default ~ income)
plotluck(Default, default ~ student)
```
</div>

3. Compute a logistic regression and interpret it.

<div class="hiddensolution">
```{r}
Default_logit <- glm(default~ ., family = binomial(link="logit"),
                     data=Default)
summary(Default_logit)
odds.ratio(Default_logit)
```
</div>

4. Use the `step` function to simplify the model.

<div class="hiddensolution">
```{r}
# backward selection with AIC
step(Default_logit,direction="backward")

Default_logit_simple <- step(Default_logit,direction="backward")
summary(Default_logit_simple)

odds.ratio(Default_logit_simple)
```
</div>

5. Compare the two models in term of prediction accuracy.

<div class="hiddensolution">
```{r}
Default_score <- predict(Default_logit, data = Default, type = "response")
Default_simple_score <- predict(Default_logit_simple, data = Default, type = "response")

Default_pred <- Default %>%
  mutate(pred = factor(as.numeric(Default_score>= .5), levels = c(0,1), labels = c("No","Yes")),
         pred_simple = factor(as.numeric(Default_simple_score>= .5), levels = c(0,1), labels = c("No","Yes")))

Default_pred %>% summarize(err = mean(pred != default),
                           err_simple = mean(pred_simple != default))
```
</div>

6. Do you obtain the same result with cross validation?

<div class="hiddensolution">
```{r}
# CV error
glm_KFold_CV <- function (D, formula, K) {
formula <- as.formula(formula)
n <- nrow(D)
Error_glm <- rep(0, K)
set.seed(1234)
ind_Fold <- sample(n) %% K + 1
for (i in 1:K){
  Dtrain <- D[ind_Fold!=i,]
  Dtest <- D[ind_Fold==i,]
  fit.glm <- glm(formula, data=Dtrain, family=binomial)
  pred.glm <- as.numeric(predict(fit.glm, Dtest, type="response") >= 0.5 )
  Error_glm[i] <- sum((as.numeric(Dtest[,"default"])-1)!= pred.glm)/nrow(Dtest)
}
mean(Error_glm)
}

Default_VC <- glm_KFold_CV(Default, "default ~ .", 5)
Default_VC

Default_simple_VC <-  glm_KFold_CV(Default,"default ~ student + balance",5)
Default_simple_VC
```
</div>


# Spam

The __kernlab__ package proposes a `spam` dataset consisting of 4601 emails collected by George Forman at Hewlett-Packards Labs. For each of them, 57 characteritics are measured (mainly frequencies of certain words and characters) as well as a spam/no spam label. The goal is to predic this label.


1. Read the data.

<div class="hiddensolution">
```{r}
library(kernlab)
data(spam)
names(spam)
summary(spam)
```
</div>

2. Compute a logistic regression and interpret it.

<div class="hiddensolution">
```{r}
fit.glm <- glm(type~.,data=spam,family=binomial)
summary(fit.glm)
```
</div>

3. What is the empirical prediction error? How does it compare to a CV error?

<div class="hiddensolution">
```{r}
score.glm <- predict(fit.glm, spam, type = "response")
pred.glm <- as.numeric(score.glm >=0.5)
pred.glm <- factor(pred.glm, levels = c(0,1), labels = c("nonspam","spam"))

Err <- mean(pred.glm != spam$type)
Err

n <- nrow(spam)
V <- 5
Vf <- sample(n) %% V + 1

ErrCV <- numeric(V)
for (v in 1:V) {
  spam.train <- spam[Vf != v, ]
  spam.test <- spam[Vf == v, ]
  fit.glm <- glm(type~.,data=spam.train,family=binomial)
  score.glm <- predict(fit.glm, spam.train, type = "response")
  pred.glm <- as.numeric(score.glm >=0.5)
  pred.glm <- factor(pred.glm, levels = c(0,1), labels = c("nonspam","spam"))

  ErrCV[v] <- mean(pred.glm != spam$type)
}
mean(ErrCV)
```
</div>

4. Compute the ROC curve with and without CV.

<div class="hiddensolution">
```{r}
#seuil s
s.glm=seq(0,1.01,.01)

absc.glm=numeric(length(s.glm));
ordo.glm=numeric(length(s.glm))

fit.glm <- glm(type~.,data=spam,family=binomial)
score.glm <- predict(fit.glm, spam, type = "response")

for (i in 1:length(s.glm)){
  ordo.glm[i]=sum( score.glm >= s.glm[i] & spam$type == "spam")/sum(spam$type == "spam")
  absc.glm[i]=sum( score.glm >= s.glm[i] & spam$type == "nonspam")/sum(spam$type =="nonspam")
}


ROC = data.frame(FPR=absc.glm, TPR=ordo.glm)

ggplot(ROC,aes(x=FPR,y=TPR)) + geom_path(color="red")  +
   geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1), linetype = 2, color = "black") 


absc.glm.CV=matrix(nrow = V, ncol = length(s.glm))
ordo.glm.CV=matrix(nrow = V, ncol = length(s.glm))

for (v in 1:V) {
  spam.train <- spam[Vf != v, ]
  spam.test <- spam[Vf == v, ]
  fit.glm <- glm(type~.,data=spam.train,family=binomial)
  score.glm <- predict(fit.glm, spam.test, type = "response")

  for (i in 1:length(s.glm)){
    ordo.glm.CV[v,i]=sum( score.glm >= s.glm[i] & spam.test$type == "spam")/sum(spam.test$type == "spam")
    absc.glm.CV[v,i]=sum( score.glm >= s.glm[i] & spam.test$type == "nonspam")/sum(spam.test$type =="nonspam")
  }
}

ordo.glm.CV <- apply(ordo.glm.CV,2,mean)
absc.glm.CV <- apply(absc.glm.CV,2,mean)

ROC.CV = data.frame(FPR=absc.glm.CV, TPR=ordo.glm.CV)

ggplot(ROC.CV,aes(x=FPR,y=TPR)) + geom_path(aes(),color="red")  +
   geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1), linetype = 2, color = "black") 

ggplot(ROC.CV,aes(x=FPR,y=TPR)) + geom_path(color="red")  + geom_path(data = ROC, color = "blue") +
   geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1), linetype = 2, color = "black")
```
</div>

5. Use `glmnet` to obtain the Lasso regularization path.

<div class="hiddensolution">
```{r Glmnet}
X <- model.matrix(type ~ ., data = spam)
Y <- spam[["type"]]

library(glmnet)
spam_lasso <- glmnet(X, Y, family = "binomial")

coeffs_spam_lasso <- cbind(data.frame(t(as.matrix(coef(spam_lasso)))),
                          lambda = spam_lasso[["lambda"]])

ggplot(data = reshape2::melt(coeffs_spam_lasso, "lambda"), aes(x = lambda, y = value, color = variable)) + geom_line()

ggplot(data = reshape2::melt(coeffs_spam_lasso, "lambda"), aes(x = lambda, y = value, color = variable)) + geom_line()  + guides(color = "none")

ggplot(data = reshape2::melt(coeffs_spam_lasso, "lambda"), aes(x = factor(lambda), y = variable, fill = log(1+abs(value)), color = log(1+abs(value)))) + geom_tile()

```
</div>

6. What is the best value for $\lambda$?

<div class="hiddensolution">
```{r}
lambda.cv <-  cv.glmnet(X,Y,family ="binomial",intercept=F)$lambda.1se

bh <- glmnet(X,Y,family ="binomial",intercept=F,lambda=lambda.cv)$beta

bh
```
</div>

7. Repeat the experiment with the  __ridge__ regression.

<div class="hiddensolution">
```{r}
spam_ridge <- glmnet(X, Y, family = "binomial", alpha = 0)

coeffs_spam_ridge <- cbind(data.frame(t(as.matrix(coef(spam_ridge)))),
                          lambda = spam_ridge[["lambda"]])

ggplot(data = reshape2::melt(coeffs_spam_ridge, "lambda"), aes(x = lambda, y = value, color = variable)) + geom_line() + guides(color = "none")

ggplot(data = reshape2::melt(coeffs_spam_ridge, "lambda"), aes(x = factor(lambda), y = variable, fill = log(1+abs(value)), color = log(1+abs(value)))) + geom_tile()

```
</div>

8. Do we obtain a gain if we use the _Lasso_ with a model including the interactions?

